import h5py
import numpy as np
import warnings
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, TensorDataset

warnings.filterwarnings('ignore')

# Set random seeds
np.random.seed(42)
torch.manual_seed(42)

# Device selection
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# ==================== 加载一维平流方程数据 ====================
print("=== LOADING ADVECTION DATA ===")
filepath = "D:/浏览器/1D_Advection_Sols_beta0.1.hdf5"

# 加载完整数据集
with h5py.File(filepath, 'r') as f:
    t_coord = f['t-coordinate'][:]  # 时间坐标 (202,)
    x_coord = f['x-coordinate'][:]  # 空间坐标 (1024,)
    u_tensor = f['tensor'][:]  # 解张量 (10000, 201, 1024)
print(f"时间坐标 t_coord: {t_coord.shape}")
print(f"空间坐标 x_coord: {x_coord.shape}")
print(f"解张量 u_tensor: {u_tensor.shape}")
t_coord_for_tensor = t_coord[1:]

print(f"使用的t_coord_for_tensor形状: {t_coord_for_tensor.shape}")


# ==================== 准备数据函数 ====================
def prepare_advection_data_3d(u_tensor, t_coord, x_coord, num_samples=1000):
    """
    准备3D平流方程数据集
    输入: u(x, t0) - 初始条件
    输出: u(x, t0+Δt) - 经过Δt时间后的解
    u_tensor形状: (num_simulations, num_time_steps, num_space_points)
    """
    num_simulations, num_time_steps, num_space_points = u_tensor.shape

    print(f"原始数据: {num_simulations}个模拟, {num_time_steps}个时间步, {num_space_points}个空间点")

    # 确保有足够的样本
    if num_samples > num_simulations * (num_time_steps - 10):
        num_samples = num_simulations * (num_time_steps - 10)

    source_functions = []  # 初始条件 + 时间信息
    solutions = []  # 目标解
    time_steps = []  # 时间间隔

    print("Generating data samples...")

    samples_per_simulation = max(1, num_samples // num_simulations)

    for sim_idx in tqdm(range(min(num_simulations, 100))):  # 限制模拟数量以加速
        if len(source_functions) >= num_samples:
            break

        # 每个模拟生成多个样本
        for _ in range(samples_per_simulation):
            if len(source_functions) >= num_samples:
                break

            # 随机选择初始时间步
            t0_idx = np.random.randint(0, num_time_steps - 10)

            # 随机选择时间间隔 (1到5个时间步，以保持Δt不会太大)
            Δt_idx = np.random.randint(1, 6)
            t1_idx = t0_idx + Δt_idx

            # 确保不超过范围
            if t1_idx >= num_time_steps:
                continue

            # 初始条件 u(x, t0)
            u0 = u_tensor[sim_idx, t0_idx, :]

            # 目标解 u(x, t1)
            u1 = u_tensor[sim_idx, t1_idx, :]

            # 时间间隔 Δt
            Δt = t_coord[t1_idx] - t_coord[t0_idx]

            # 组合输入: [初始条件, 时间间隔]
            source_input = np.concatenate([u0, [Δt]])

            source_functions.append(source_input)
            solutions.append(u1)
            time_steps.append(Δt)

    # 如果样本不够，再随机采样一些
    while len(source_functions) < num_samples:
        sim_idx = np.random.randint(0, num_simulations)
        t0_idx = np.random.randint(0, num_time_steps - 10)
        Δt_idx = np.random.randint(1, 6)
        t1_idx = t0_idx + Δt_idx

        if t1_idx >= num_time_steps:
            continue

        u0 = u_tensor[sim_idx, t0_idx, :]
        u1 = u_tensor[sim_idx, t1_idx, :]
        Δt = t_coord[t1_idx] - t_coord[t0_idx]

        source_input = np.concatenate([u0, [Δt]])
        source_functions.append(source_input)
        solutions.append(u1)
        time_steps.append(Δt)

    source_functions = np.array(source_functions)
    solutions = np.array(solutions)

    print(f"生成 {len(source_functions)} 个样本")
    print(f"输入维度: {source_functions.shape}")
    print(f"输出维度: {solutions.shape}")
    print(f"时间间隔范围: [{np.min(time_steps):.4f}, {np.max(time_steps):.4f}]")
    print(f"平均时间间隔: {np.mean(time_steps):.4f}")

    return x_coord, source_functions, solutions


# 准备数据
print("\n=== PREPARING 3D ADVECTION DATA ===")
x, source_functions, solutions = prepare_advection_data_3d(
    u_tensor, t_coord_for_tensor, x_coord, num_samples=2000
)

# ==================== 可视化示例数据 ====================
print("\n=== VISUALIZING SAMPLE DATA ===")
fig, axes = plt.subplots(2, 3, figsize=(15, 10))
for i in range(6):
    ax = axes[i // 3, i % 3]

    # 提取初始条件 (排除最后的时间信息)
    initial_condition = source_functions[i, :-1]
    target_solution = solutions[i]
    Δt = source_functions[i, -1]

    ax.plot(x, initial_condition, 'g-', linewidth=2, label=f'u(x, t0)', alpha=0.8)
    ax.plot(x, target_solution, 'b-', linewidth=2, label=f'u(x, t0+{Δt:.3f})', alpha=0.8)

    ax.set_title(f'Sample {i + 1}, Δt = {Δt:.3f}')
    ax.grid(True, alpha=0.3)
    ax.legend()
    ax.set_xlabel('x')
    ax.set_ylabel('u(x,t)')
    ax.set_xlim([x[0], x[-1]])

plt.tight_layout()
plt.show()


class AdvectionPhysicsInformedDeepONet(nn.Module):
    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dim=128, num_basis=64):
        super(AdvectionPhysicsInformedDeepONet, self).__init__()
        self.num_basis = num_basis
        self.hidden_dim = hidden_dim

        # Branch network: 处理初始条件 + 时间间隔
        # 输入: [u0(x), Δt]
        self.branch_net = nn.Sequential(
            nn.Linear(branch_input_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, num_basis)
        )

        # Trunk network: 处理空间坐标
        # 输入: x
        self.trunk_net = nn.Sequential(
            nn.Linear(trunk_input_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, num_basis)
        )

        # Bias term
        self.bias = nn.Parameter(torch.zeros(1))

        # 平流速度 (可学习参数)
        self.advection_speed = nn.Parameter(torch.tensor(1.0))

    def forward(self, branch_input, trunk_input):
        """Forward pass"""
        # Branch network output
        branch_out = self.branch_net(branch_input)  # [batch_size, num_basis]

        # Trunk network output - 修正：确保梯度不中断
        if trunk_input.dim() == 3:  # [batch_size, num_points, 1]
            batch_size, num_points, _ = trunk_input.shape
            trunk_input_flat = trunk_input.reshape(-1, 1)  # 保持梯度追踪
            trunk_out = self.trunk_net(trunk_input_flat)
            trunk_out = trunk_out.reshape(batch_size, num_points, self.num_basis)
        else:  # [num_points, 1]
            trunk_out = self.trunk_net(trunk_input)
            trunk_out = trunk_out.unsqueeze(0)

        # Compute inner product
        output = torch.einsum('bi,bpi->bp', branch_out, trunk_out)

        return output + self.bias

    def compute_derivatives(self, branch_input, trunk_input, is_training=False):
        """
        计算时空导数（修复反向传播二次图错误）
        branch_input: [batch_size, num_space_points + 1] (u0 + Δt)
        trunk_input: [batch_size, num_points, 1] (x)
        is_training: 是否训练阶段（决定是否保留计算图）
        """
        # 统一克隆张量，避免原地修改导致的梯度追踪异常
        trunk_input = trunk_input.clone().requires_grad_(True)

        # 前向传播
        u = self.forward(branch_input, trunk_input)

        # 计算空间导数 ∂u/∂x
        du_dx = torch.autograd.grad(
            outputs=u,
            inputs=trunk_input,
            grad_outputs=torch.ones_like(u, device=u.device),
            create_graph=is_training,  # 训练阶段创建图，验证阶段不创建
            retain_graph=is_training,  # 训练阶段保留图，验证阶段释放
            allow_unused=True,
            only_inputs=True
        )[0]

        return u, du_dx, self.advection_speed


def advection_physics_loss(model, branch_input, x_input, u_true,
                           lambda_physics=0.5, lambda_boundary=5.0,
                           lambda_speed=0.01, compute_physics=True, is_training=False):
    """
    一维平流方程物理损失函数（增加is_training参数）
    is_training: 是否训练阶段（传递给compute_derivatives）
    """
    if compute_physics:
        x_input = x_input.to(device)
        # 核心：传递is_training参数，控制计算图
        u_pred, du_dx, advection_speed = model.compute_derivatives(branch_input, x_input, is_training=is_training)

        # 数据损失
        data_loss = torch.mean((u_pred - u_true) ** 2)

        # 物理损失（处理du_dx为None的情况）
        batch_size, num_points = u_pred.shape
        initial_condition = branch_input[:, :-1]
        Δt = branch_input[:, -1].unsqueeze(-1) + 1e-6  # 防除零
        time_derivative = (u_pred - initial_condition) / Δt

        # 处理du_dx为空
        if du_dx is None:
            du_dx_squeezed = torch.zeros_like(u_pred)
        else:
            du_dx_squeezed = du_dx.squeeze(-1)

        physics_residual = time_derivative + advection_speed * du_dx_squeezed
        physics_loss = torch.mean(physics_residual ** 2)

        # 边界损失
        u_left = u_pred[:, 0]
        u_right = u_pred[:, -1]
        boundary_loss = torch.mean((u_left - u_right) ** 2)

        # 速度正则化（修正：标量无需mean，提升效率）
        speed_loss = (advection_speed ** 2) * lambda_speed

    else:
        u_pred = model(branch_input, x_input)
        data_loss = torch.mean((u_pred - u_true) ** 2)
        physics_loss = torch.tensor(0.0, device=u_pred.device)
        boundary_loss = torch.tensor(0.0, device=u_pred.device)
        speed_loss = torch.tensor(0.0, device=u_pred.device)

    total_loss = data_loss + lambda_physics * physics_loss + lambda_boundary * boundary_loss + speed_loss
    return total_loss, data_loss, physics_loss, boundary_loss, speed_loss


# ==================== 数据加载器 ====================
def setup_advection_data_loaders(source_functions, solutions, x, batch_size=16):
    """设置平流方程数据加载器"""
    # 划分数据集
    total_samples = len(source_functions)
    train_size = int(0.8 * total_samples)
    val_size = int(0.1 * total_samples)

    train_sources = source_functions[:train_size]
    train_solutions = solutions[:train_size]

    val_sources = source_functions[train_size:train_size + val_size]
    val_solutions = solutions[train_size:train_size + val_size]

    test_sources = source_functions[train_size + val_size:]
    test_solutions = solutions[train_size + val_size:]

    print(f"训练集: {len(train_sources)} 样本")
    print(f"验证集: {len(val_sources)} 样本")
    print(f"测试集: {len(test_sources)} 样本")

    # 转换为张量
    x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(1)

    # 创建数据集
    train_x = x_tensor.unsqueeze(0).repeat(len(train_sources), 1, 1)
    val_x = x_tensor.unsqueeze(0).repeat(len(val_sources), 1, 1)

    train_dataset = TensorDataset(
        torch.tensor(train_sources, dtype=torch.float32),
        train_x,
        torch.tensor(train_solutions, dtype=torch.float32)
    )

    val_dataset = TensorDataset(
        torch.tensor(val_sources, dtype=torch.float32),
        val_x,
        torch.tensor(val_solutions, dtype=torch.float32)
    )

    # 使用较小的batch_size处理大数据
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)

    test_data = (test_sources, test_solutions, x)

    return train_loader, val_loader, test_data


# ==================== 训练函数 ====================
def train_advection_deeponet(model, train_loader, val_loader,
                             num_epochs=1000, lr=0.001,
                             lambda_physics=0.5, lambda_boundary=5.0, lambda_speed=0.01):
    """训练平流方程DeepONet（修复反向传播二次图错误）"""
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=20, factor=0.5)

    # 存储损失
    train_losses = {'total': [], 'data': [], 'physics': [], 'boundary': [], 'speed': []}
    val_losses = {'total': [], 'data': [], 'physics': [], 'boundary': [], 'speed': []}

    best_val_loss = float('inf')
    patience = 30
    patience_counter = 0

    pbar = tqdm(range(num_epochs), desc="Training Advection DeepONet")

    for epoch in pbar:
        # 训练阶段
        model.train()
        train_loss_epoch = {'total': 0, 'data': 0, 'physics': 0, 'boundary': 0, 'speed': 0}

        for batch_sources, batch_x, batch_solutions in train_loader:
            batch_sources = batch_sources.to(device)
            batch_x = batch_x.to(device)
            batch_solutions = batch_solutions.to(device)

            optimizer.zero_grad()  # 清空梯度

            # 训练阶段：传递is_training=True，保留计算图
            total_loss, data_loss, physics_loss, boundary_loss, speed_loss = advection_physics_loss(
                model, batch_sources, batch_x, batch_solutions,
                lambda_physics=lambda_physics,
                lambda_boundary=lambda_boundary,
                lambda_speed=lambda_speed,
                compute_physics=True,
                is_training=True  # 核心：训练阶段标识
            )

            # 反向传播（此时计算图已保留，可正常执行）
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            # 累加损失（取item，释放张量）
            train_loss_epoch['total'] += total_loss.item()
            train_loss_epoch['data'] += data_loss.item()
            train_loss_epoch['physics'] += physics_loss.item()
            train_loss_epoch['boundary'] += boundary_loss.item()
            train_loss_epoch['speed'] += speed_loss.item()

        # 验证阶段
        model.eval()
        val_loss_epoch = {'total': 0, 'data': 0, 'physics': 0, 'boundary': 0, 'speed': 0}

        # 修正1：嵌套enable_grad()，允许计算导数但不更新参数
        with torch.no_grad():  # 禁用参数梯度更新
            for batch_sources, batch_x, batch_solutions in val_loader:
                batch_sources = batch_sources.to(device)
                batch_x = batch_x.to(device)
                batch_solutions = batch_solutions.to(device)

                # 临时启用梯度计算物理损失
                with torch.enable_grad():
                    total_loss, data_loss, physics_loss, boundary_loss, speed_loss = advection_physics_loss(
                        model, batch_sources, batch_x, batch_solutions,
                        lambda_physics=lambda_physics,
                        lambda_boundary=lambda_boundary,
                        lambda_speed=lambda_speed,
                        compute_physics=True,
                        is_training=False  # 核心：验证阶段标识
                    )

                val_loss_epoch['total'] += total_loss.item()
                val_loss_epoch['data'] += data_loss.item()
                val_loss_epoch['physics'] += physics_loss.item()
                val_loss_epoch['boundary'] += boundary_loss.item()
                val_loss_epoch['speed'] += speed_loss.item()

        # 计算平均损失
        for key in train_loss_epoch:
            train_loss_epoch[key] /= len(train_loader)
            val_loss_epoch[key] /= len(val_loader)
            train_losses[key].append(train_loss_epoch[key])
            val_losses[key].append(val_loss_epoch[key])

        scheduler.step(val_loss_epoch['total'])

        # 更新进度条
        pbar.set_postfix({
            'Train': f'{train_loss_epoch["total"]:.2e}',
            'Val': f'{val_loss_epoch["total"]:.2e}',
            'Data': f'{train_loss_epoch["data"]:.2e}',
            'Phys': f'{train_loss_epoch["physics"]:.2e}',
            'Speed': f'{model.advection_speed.item():.4f}',
            'LR': f'{optimizer.param_groups[0]["lr"]:.2e}'
        })



    pbar.close()

    # 加载最佳模型
    try:
        checkpoint = torch.load('best_advection_model.pth', map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        print(f"Loaded best model from epoch {checkpoint['epoch']}")
    except Exception as e:
        print(f"Warning: Could not load best model - {e}, using current model")

    return train_losses, val_losses


# ==================== 主程序 ====================
if __name__ == "__main__":
    # 创建模型
    print("\n=== CREATING ADVECTION DEEPONET ===")
    branch_input_dim = source_functions.shape[1]  # u0 + Δt
    trunk_input_dim = 1  # x坐标

    model = AdvectionPhysicsInformedDeepONet(
        branch_input_dim=branch_input_dim,
        trunk_input_dim=trunk_input_dim,
        hidden_dim=128,
        num_basis=64
    ).to(device)

    total_params = sum(p.numel() for p in model.parameters())
    print(f"模型总参数量: {total_params:,}")
    print(f"分支网络输入维度: {branch_input_dim}")
    print(f"主干网络输入维度: {trunk_input_dim}")
    print(f"空间点数: {len(x)}")
    print(f"初始平流速度: {model.advection_speed.item():.4f}")

    # 设置数据加载器
    print("\n=== SETTING UP DATA LOADERS ===")
    train_loader, val_loader, test_data = setup_advection_data_loaders(
        source_functions, solutions, x, batch_size=16
    )

    # 训练模型（修正：降低物理损失权重，避免梯度爆炸）
    print("\n=== STARTING TRAINING ===")
    train_losses, val_losses = train_advection_deeponet(
        model, train_loader, val_loader,
        num_epochs=1000, lr=0.001,  # 降低学习率，提升稳定性
        lambda_physics=0.5,  # 降低物理损失权重，先拟合数据
        lambda_boundary=5,  # 降低边界损失权重
        lambda_speed=0.01  # 降低速度正则化权重
    )

    # 可视化训练历史
    print("\n=== TRAINING HISTORY ===")
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))

    losses_to_plot = ['total', 'data', 'physics', 'boundary', 'speed']
    titles = ['Total Loss', 'Data Loss', 'Physics Loss', 'Boundary Loss', 'Speed Regularization']
    for idx, (loss_key, title) in enumerate(zip(losses_to_plot, titles)):
        ax = axes[idx // 3, idx % 3]
        train_vals = np.array(train_losses[loss_key]) + 1e-8  # 防对数刻度下的0值
        val_vals = np.array(val_losses[loss_key]) + 1e-8

        ax.plot(train_vals, label='Train', alpha=0.8, linewidth=2)
        ax.plot(val_vals, label='Val', alpha=0.8, linewidth=2, color='orange')  # 橙色更显眼
        ax.set_title(title, fontsize=12)
        ax.set_xlabel('Epoch', fontsize=10)
        ax.set_ylabel('Loss', fontsize=10)
        ax.set_yscale('log')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=9)
        ax.tick_params(axis='both', which='major', labelsize=9)
    # 绘制平流速度变化
    ax = axes[1, 2]
    ax.set_title('Learned Advection Speed', fontsize=12)
    ax.text(0.5, 0.5, f'c = {model.advection_speed.item():.4f}',
            ha='center', va='center', fontsize=20, transform=ax.transAxes)
    ax.axis('off')

    plt.tight_layout()
    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')
    plt.show()

    # ==================== 模型评估 ====================
    print("\n=== MODEL EVALUATION ===")
    test_sources, test_solutions, test_x = test_data

    model.eval()
    predictions = []
    physics_residuals = []
    l2_errors = []
    boundary_errors = []

    print(f"Evaluating {len(test_sources)} test samples...")

    # 移除全局no_grad()，改为仅在不需要梯度的地方局部使用
    for i in tqdm(range(min(100, len(test_sources)))):  # 评估前100个测试样本
        # 准备输入
        source_tensor = torch.tensor(test_sources[i:i + 1], dtype=torch.float32).to(device)
        x_tensor = torch.tensor(test_x, dtype=torch.float32).unsqueeze(1).unsqueeze(0).to(device)

        # 1. 预测（不需要梯度，局部no_grad）
        with torch.no_grad():
            u_pred = model(source_tensor, x_tensor)
            u_pred_np = u_pred.cpu().numpy().flatten()
        predictions.append(u_pred_np)

        # 2. 计算物理残差（需要梯度，临时启用）
        with torch.enable_grad():  # 临时启用梯度计算
            # 修正2：传递is_training=False，避免保留计算图
            u_pred_grad, du_dx, advection_speed = model.compute_derivatives(
                source_tensor, x_tensor, is_training=False
            )

        # 计算物理残差
        initial_condition = test_sources[i, :-1]
        Δt = test_sources[i, -1]
        time_derivative = (u_pred_np - initial_condition) / (Δt + 1e-6)  # 加小常数防除零
        du_dx_np = du_dx.detach().cpu().numpy().flatten() if du_dx is not None else np.zeros_like(u_pred_np)
        physics_residual = time_derivative + advection_speed.detach().cpu().numpy() * du_dx_np
        physics_residuals.append(physics_residual)

        # 计算误差（不需要梯度）
        with torch.no_grad():
            l2_error = np.sqrt(np.mean((u_pred_np - test_solutions[i]) ** 2))
            l2_errors.append(l2_error)
            boundary_error = np.abs(u_pred_np[0] - u_pred_np[-1])
            boundary_errors.append(boundary_error)

    # 统计结果
    avg_l2_error = np.mean(l2_errors)
    avg_physics_residual = np.mean([np.mean(np.abs(res)) for res in physics_residuals])
    avg_boundary_error = np.mean(boundary_errors)

    print(f"\n=== EVALUATION RESULTS ===")
    print(f"  Average L2 Error: {avg_l2_error:.6f}")
    print(f"  Average Physics Residual: {avg_physics_residual:.6f}")
    print(f"  Average Boundary Error: {avg_boundary_error:.6f}")
    print(f"  Learned Advection Speed: {advection_speed.item():.6f}")
    print(f"  Tested {len(l2_errors)} samples")

    # ==================== 可视化测试结果 ====================
    print("\n=== TEST RESULTS VISUALIZATION ===")
    n_test_plots = min(6, len(predictions))
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))

    for i in range(n_test_plots):
        ax = axes[i // 3, i % 3]

        # 提取数据
        initial_condition = test_sources[i, :-1]
        Δt = test_sources[i, -1]
        target_solution = test_solutions[i]
        prediction = predictions[i]

        # 绘制结果
        ax.plot(test_x, initial_condition, 'g-', linewidth=2, label='u(x, t0)', alpha=0.7)
        ax.plot(test_x, target_solution, 'b-', linewidth=2, label='True u(x, t1)', alpha=0.8)
        ax.plot(test_x, prediction, 'r--', linewidth=2, label='Predicted u(x, t1)', alpha=0.8)

        # 误差信息
        l2_err = l2_errors[i]
        phys_err = np.mean(np.abs(physics_residuals[i]))

        ax.set_title(f'Test {i + 1}: Δt={Δt:.3f}\nL2={l2_err:.4f}, Phys={phys_err:.2e}', fontsize=10)
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=9)
        ax.set_xlabel('x', fontsize=10)
        ax.set_ylabel('u(x,t)', fontsize=10)
        ax.set_xlim([test_x[0], test_x[-1]])
        ax.tick_params(axis='both', which='major', labelsize=8)

    plt.tight_layout()
    plt.savefig('test_predictions.png', dpi=150, bbox_inches='tight')
    plt.show()

    # ==================== 误差分布 ====================
    print("\n=== ERROR DISTRIBUTION ===")
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    # L2误差分布
    axes[0].hist(l2_errors, bins=20, alpha=0.7, edgecolor='black', density=True)
    axes[0].axvline(np.mean(l2_errors), color='red', linestyle='--',
                    label=f'Mean: {np.mean(l2_errors):.4f}', linewidth=2)
    axes[0].set_title('L2 Error Distribution', fontsize=12)
    axes[0].set_xlabel('L2 Error', fontsize=10)
    axes[0].set_ylabel('Density', fontsize=10)
    axes[0].legend(fontsize=9)
    axes[0].grid(True, alpha=0.3)
    axes[0].tick_params(axis='both', which='major', labelsize=8)

    # 物理残差分布
    physics_residual_means = [np.mean(np.abs(res)) for res in physics_residuals]
    axes[1].hist(physics_residual_means, bins=20, alpha=0.7, edgecolor='black', density=True)
    axes[1].axvline(np.mean(physics_residual_means), color='red', linestyle='--',
                    label=f'Mean: {np.mean(physics_residual_means):.4f}', linewidth=2)
    axes[1].set_title('Physics Residual Distribution', fontsize=12)
    axes[1].set_xlabel('Mean |Physics Residual|', fontsize=10)
    axes[1].set_ylabel('Density', fontsize=10)
    axes[1].legend(fontsize=9)
    axes[1].grid(True, alpha=0.3)
    axes[1].tick_params(axis='both', which='major', labelsize=8)

    # 边界误差分布
    axes[2].hist(boundary_errors, bins=20, alpha=0.7, edgecolor='black', density=True)
    axes[2].axvline(np.mean(boundary_errors), color='red', linestyle='--',
                    label=f'Mean: {np.mean(boundary_errors):.4f}', linewidth=2)
    axes[2].set_title('Boundary Error Distribution', fontsize=12)
    axes[2].set_xlabel('|u(0)-u(L)|', fontsize=10)
    axes[2].set_ylabel('Density', fontsize=10)
    axes[2].legend(fontsize=9)
    axes[2].grid(True, alpha=0.3)
    axes[2].tick_params(axis='both', which='major', labelsize=8)

    plt.tight_layout()
    plt.savefig('error_distributions.png', dpi=150, bbox_inches='tight')
    plt.show()

    # ==================== 物理残差空间分布 ====================
    print("\n=== PHYSICS RESIDUAL SPATIAL DISTRIBUTION ===")
    n_residual_plots = min(3, len(physics_residuals))
    fig, axes = plt.subplots(n_residual_plots, 1, figsize=(12, 3 * n_residual_plots))

    if n_residual_plots == 1:
        axes = [axes]

    for i in range(n_residual_plots):
        ax = axes[i]
        ax.plot(test_x, physics_residuals[i], 'purple', linewidth=1.5, alpha=0.8)
        ax.axhline(y=0, color='k', linestyle='-', linewidth=0.5, alpha=0.5)
        ax.fill_between(test_x, physics_residuals[i], 0, where=(physics_residuals[i] >= 0),
                        color='red', alpha=0.3, interpolate=True)
        ax.fill_between(test_x, physics_residuals[i], 0, where=(physics_residuals[i] <= 0),
                        color='blue', alpha=0.3, interpolate=True)

        mean_res = np.mean(np.abs(physics_residuals[i]))
        ax.set_title(f'Physics Residual Sample {i + 1} (Mean |Res| = {mean_res:.2e})', fontsize=10)
        ax.set_xlabel('x', fontsize=10)
        ax.set_ylabel('PDE Residual', fontsize=10)
        ax.grid(True, alpha=0.3)
        ax.tick_params(axis='both', which='major', labelsize=8)
        ax.set_xlim([test_x[0], test_x[-1]])

    plt.tight_layout()
    plt.savefig('physics_residuals.png', dpi=150, bbox_inches='tight')
    plt.show()

    # ==================== 总结 ====================
    print("\n" + "=" * 50)
    print("TRAINING COMPLETE - SUMMARY")
    print("=" * 50)
    print(f"Model Architecture:")
    print(f"  - Branch input dim: {branch_input_dim}")
    print(f"  - Trunk input dim: {trunk_input_dim}")
    print(f"  - Hidden dim: 128")
    print(f"  - Basis functions: 64")
    print(f"  - Total parameters: {total_params:,}")

    print(f"\nTraining Results:")
    print(f"  - Final train loss: {train_losses['total'][-1]:.2e}")
    print(f"  - Final val loss: {val_losses['total'][-1]:.2e}")
    print(f"  - Learned advection speed: {model.advection_speed.item():.6f}")

    print(f"\nTest Performance:")
    print(f"  - Avg L2 error: {avg_l2_error:.6f}")
    print(f"  - Avg PDE residual: {avg_physics_residual:.6f}")
    print(f"  - Avg boundary error: {avg_boundary_error:.6f}")
    print(f"  - Samples evaluated: {len(l2_errors)}")

    print(f"\nData Statistics:")
    print(f"  - Total samples: {len(source_functions)}")
    print(f"  - Train/Val/Test split: 80%/10%/10%")
    print(f"  - Spatial resolution: {len(x)} points")
    print(f"  - Time step range: 0.01-0.05")
    print(f"  - Avg time step: {np.mean([s[-1] for s in source_functions]):.4f}")

    print("\n" + "=" * 50)
    print("All plots have been saved as PNG files:")
    print("  - training_history.png")
    print("  - test_predictions.png")
    print("  - error_distributions.png")
    print("  - physics_residuals.png")
    print("=" * 50)
